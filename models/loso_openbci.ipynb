{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "game_emotions = {1: 'front', 2: 'left', 3: 'right'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = \"/Users/mercy/Downloads/eeg/dataset_creation/datasets/all_splits\"\n",
    "\n",
    "# List to store extracted data\n",
    "data = []\n",
    "\n",
    "# Iterate through files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):  # Ensure it's a CSV file\n",
    "        filename_copy = filename\n",
    "        parts = filename.split(\"_\")  # Split the filename by '_'\n",
    "        subject = parts[0] + \"_\" + parts[1]  # Combine first two parts (e.g., \"1_MB\")\n",
    "        trial = parts[2]  # Extract trial\n",
    "        trial_number = parts[3]  # Extract trial number\n",
    "        label = parts[4].replace(\".csv\", \"\")  # Remove .csv extension\n",
    "        \n",
    "        # Append to the list\n",
    "        data.append([subject, trial, trial_number, label, filename_copy])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(data, columns=[\"subject\", \"trial\", \"trial_num\", \"label\", 'filename'])\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_windows(df, window_size=100, step_size=50):\n",
    "    windows = []\n",
    "    for i in range(0, len(df) - window_size + 1, step_size):\n",
    "        window = df.iloc[i:i + window_size].values\n",
    "        windows.append(window)\n",
    "    return np.array(windows)\n",
    "\n",
    "# Organizing subjects for loso / normalizing data\n",
    "subject_data = {}\n",
    "subjects = ['1_MB', '2_FA', '3_FJ', '4_MG', '5_CB', '6_FC']\n",
    "for subject in subjects:\n",
    "    subject_str = f\"{subject:02d}\"\n",
    "    all_subject_windows = []\n",
    "    all_subject_labels = []\n",
    "    for game in range(1, 5):\n",
    "        # path = rf\"C:\\eeg\\Dataset - Emotion Recognition data Based on EEG Signals and Computer Games\\Database for Emotion Recognition System Based on EEG Signals and Various Computer Games - GAMEEMO\\GAMEEMO\\(S{subject_str})\\Preprocessed EEG Data\\.csv format\\S{subject_str}G{game}AllChannels.csv\"\n",
    "        try:\n",
    "            game_data = df\n",
    "            game_data = game_data.drop(columns=['Unnamed: 14'], errors='ignore')\n",
    "            game_data = game_data.fillna(method='ffill')\n",
    "            game_data = (game_data - game_data.mean()) / game_data.std()\n",
    "            windows = make_windows(game_data)\n",
    "            labels = [game_emotions[game]] * len(windows)\n",
    "            all_subject_windows.append(windows)\n",
    "            all_subject_labels.extend(labels)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    if all_subject_windows:\n",
    "        subject_data[subject] = (np.concatenate(all_subject_windows, axis=0), np.array(all_subject_labels))\n",
    "\n",
    "\n",
    "# Masked autoencoder function\n",
    "def masked_autoencoder(input_shape=(100, 14, 1), mask_ratio=0.25):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Generate mask (correct shape for data)\n",
    "    mask = tf.cast(tf.random.uniform(shape=(1, 100, 14, 1)) > mask_ratio, dtype=tf.float32)\n",
    "    masked_inputs = layers.Multiply()([inputs, mask])  # Ensure element-wise multiplication works\n",
    "\n",
    "    # Encoder\n",
    "    encoder = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu')\n",
    "    ])\n",
    "    encoded = encoder(masked_inputs)\n",
    "\n",
    "    # Decoder\n",
    "    decoder = models.Sequential([\n",
    "        layers.Dense(100 * 14, activation='relu'),\n",
    "        layers.Reshape((100, 14, 1)),\n",
    "        layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')  # Ensure final shape matches input\n",
    "    ])\n",
    "    decoded = decoder(encoded)\n",
    "\n",
    "    autoencoder = models.Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')  # MSE for reconstruction\n",
    "\n",
    "    return autoencoder, encoder\n",
    "\n",
    "\n",
    "# Actual CNN model (with pretrained encoder from above)\n",
    "def cnn_model(pretrained_encoder):\n",
    "    inputs = layers.Input(shape=(100, 14, 1))\n",
    "    features = pretrained_encoder(inputs)\n",
    "    dense_layer = layers.Dense(64, activation='relu')(features)\n",
    "    dropout_layer = layers.Dropout(0.3)(dense_layer)\n",
    "    output_layer = layers.Dense(4, activation='softmax')(dropout_layer)\n",
    "    model = models.Model(inputs, output_layer)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training/Testing\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "all_labels = np.concatenate([labels for _, labels in subject_data.values()])\n",
    "le.fit(all_labels)\n",
    "\n",
    "mae, encoder = masked_autoencoder()\n",
    "mae.summary()\n",
    "\n",
    "# Train autoencoder\n",
    "mae, encoder = masked_autoencoder()\n",
    "all_data = np.concatenate([data for data, _ in subject_data.values()], axis=0).reshape(-1, 100, 14, 1)\n",
    "mae.fit(all_data, all_data, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "loso_accuracies = []\n",
    "for test_subject in subject_data.keys():\n",
    "    train_data = [data for subj, (data, _) in subject_data.items() if subj != test_subject]\n",
    "    train_labels = [labels for subj, (_, labels) in subject_data.items() if subj != test_subject]\n",
    "    if not train_data:\n",
    "        continue\n",
    "    X_train = np.concatenate(train_data, axis=0).reshape(-1, 100, 14, 1)\n",
    "    y_train = np.concatenate(train_labels, axis=0)\n",
    "    y_train = le.transform(y_train)\n",
    "    y_train = to_categorical(y_train)\n",
    "    \n",
    "    X_test, y_test = subject_data[test_subject]\n",
    "    X_test = X_test.reshape(-1, 100, 14, 1)\n",
    "    y_test = le.transform(y_test)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    model = cnn_model(encoder)\n",
    "    model.fit(X_train, y_train, epochs=10, verbose=1)\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    loso_accuracies.append(test_accuracy)\n",
    "    print(f\"Subject {test_subject} Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Print accuracies\n",
    "if loso_accuracies:\n",
    "    print(f\"\\nFinal LOSO Accuracy: {np.mean(loso_accuracies):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qmind2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
